## Mon 25 Nov

```python
# Подберём какой-нибудь grad_output
>>> grad_output
tensor([[0.5639, 3.9705, 3.1181, 2.8139, 4.6823, 2.2522, 0.8280, 4.8762],
        [4.6377, 4.6369, 1.3571, 0.6602, 2.5575, 0.2618, 3.2754, 3.5749],
        [4.1937, 2.7525, 4.2534, 2.3367, 0.1365, 4.4054, 3.5968, 0.2089],
        [4.8664, 2.7358, 1.0065, 3.9562, 0.1063, 2.4455, 4.2698, 0.9564],
        [3.3736, 2.6553, 0.1529, 3.7679, 1.6138, 2.9129, 0.4206, 1.7545],
        [3.3813, 1.5278, 2.0262, 3.0295, 1.9350, 4.7189, 2.9043, 1.8229],
        [2.0115, 4.2073, 4.8382, 1.2035, 2.6603, 0.0444, 2.2832, 3.0582],
        [1.4882, 4.6769, 4.6872, 4.0702, 2.6707, 4.7058, 4.2222, 2.2419]])

# Пробуем вызвать backward
>>> CustomReLUFunction.backward(ctx, grad_output)
(tensor([[0.5639, 3.9705, 3.1181, 2.8139, 4.6823, 2.2522, 0.8280, 4.8762],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [4.1937, 2.7525, 4.2534, 2.3367, 0.1365, 4.4054, 3.5968, 0.2089],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [3.3736, 2.6553, 0.1529, 3.7679, 1.6138, 2.9129, 0.4206, 1.7545],
         [3.3813, 1.5278, 2.0262, 3.0295, 1.9350, 4.7189, 2.9043, 1.8229],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [1.4882, 4.6769, 4.6872, 4.0702, 2.6707, 4.7058, 4.2222, 2.2419]]),
 None)

# Пробуем вызвать backward ещё раз
>>> CustomReLUFunction.backward(ctx, grad_output)
(tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
         [3.3736, 2.6553, 0.1529, 3.7679, 1.6138, 2.9129, 0.4206, 1.7545],
         [3.3813, 1.5278, 2.0262, 3.0295, 1.9350, 4.7189, 2.9043, 1.8229],
         [2.0115, 4.2073, 4.8382, 1.2035, 2.6603, 0.0444, 2.2832, 3.0582],
         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]),
 None)
```
- [x] ~~Почему это происходит?~~
- [x] ~~Посмотреть, какие числа на самом деле~~


```python
>>> grad_input[input <= 0] = 0
>>> grad_input
tensor([[4.0976, 1.2063, 4.4080, 1.9184, 3.9247, 4.3852, 1.8739, 3.2056],
        [4.9707, 3.6839, 3.0670, 0.8438, 1.0832, 4.8114, 2.4254, 0.4293],
        [4.6633, 1.8874, 2.2397, 4.5531, 1.1717, 1.1506, 2.6788, 3.3964],
        [2.0778, 4.9428, 3.0127, 1.2335, 0.3058, 0.7436, 4.9093, 4.1225],
        [0.8547, 4.1353, 4.5385, 1.4948, 3.5989, 1.0831, 4.7478, 1.6307],
        [4.6449, 0.3148, 4.3531, 4.6925, 2.0194, 1.0407, 0.6546, 3.8230],
        [2.0546, 2.1975, 0.6902, 0.3779, 2.7731, 1.8490, 4.7318, 4.1164],
        [4.7610, 3.8396, 4.7812, 0.1429, 3.3027, 2.6181, 4.1849, 0.6450]])
>>> bernoulli_mask = torch.bernoulli(torch.ones(grad_input.size(0), device=grad_output.device) * (1 - p.item()))
>>> bernoulli_mask
tensor([1., 1., 0., 0., 1., 1., 0., 1.])
>>> diagonal_mask = torch.diag(bernoulli_mask)
>>> diagonal_mask
tensor([[1., 0., 0., 0., 0., 0., 0., 0.],
        [0., 1., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 1.]])
>>> grad_input = diagonal_mask @ grad_input
>>> grad_input
tensor([[4.0976, 1.2063, 4.4080, 1.9184, 3.9247, 4.3852, 1.8739, 3.2056],
        [4.9707, 3.6839, 3.0670, 0.8438, 1.0832, 4.8114, 2.4254, 0.4293],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.8547, 4.1353, 4.5385, 1.4948, 3.5989, 1.0831, 4.7478, 1.6307],
        [4.6449, 0.3148, 4.3531, 4.6925, 2.0194, 1.0407, 0.6546, 3.8230],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [4.7610, 3.8396, 4.7812, 0.1429, 3.3027, 2.6181, 4.1849, 0.6450]])
ON THE OTHER HAND:
>>> grad_input @ diagonal_mask 
tensor([[4.0976, 1.2063, 0.0000, 0.0000, 3.9247, 4.3852, 0.0000, 3.2056],
        [4.9707, 3.6839, 0.0000, 0.0000, 1.0832, 4.8114, 0.0000, 0.4293],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.8547, 4.1353, 0.0000, 0.0000, 3.5989, 1.0831, 0.0000, 1.6307],
        [4.6449, 0.3148, 0.0000, 0.0000, 2.0194, 1.0407, 0.0000, 3.8230],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [4.7610, 3.8396, 0.0000, 0.0000, 3.3027, 2.6181, 0.0000, 0.6450]])
```

Небольшое количество ячеек отличаются. Это 

