{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by https://web.stanford.edu/class/cs224n/index.html#coursework\n",
    "\n",
    "### Assignment Overview:\n",
    "1. **Neural Machine Translation (NMT)**: This involves training a model to translate text from one language to another.\n",
    "2. **Sequence-to-Sequence (Seq2Seq)**: Seq2Seq models are based on an encoder-decoder architecture, where the encoder processes the input sequence and the decoder generates the output sequence.\n",
    "3. **Attention Mechanism**: The attention mechanism allows the model to focus on specific parts of the input sequence when generating each part of the output sequence, addressing limitations of the basic Seq2Seq architecture.\n",
    "4. **Subwords (Byte Pair Encoding, BPE)**: Subword tokenization methods like BPE are used to break down words into smaller, more manageable units, reducing the vocabulary size and helping with rare word translations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Steps to Implement the Project:\n",
    "\n",
    "We'll need a variety of libraries and tools, so let's start by identifying the key components of the project:\n",
    "\n",
    "1. **Data Preprocessing**:\n",
    "   - Tokenize and preprocess data using libraries like `SentencePiece`, `BPE` (Byte Pair Encoding), or `SubwordNMT`.\n",
    "   - Use `nltk` for general text processing and `spaCy` for language-specific tokenization.\n",
    "\n",
    "2. **Model Implementation**:\n",
    "   - **Encoder-Decoder with Attention**:\n",
    "     - Use `TensorFlow` or `PyTorch` to implement the sequence-to-sequence architecture with attention mechanisms.\n",
    "     - For attention, you can use the `Bahdanau` or `Luong` attention variants.\n",
    "   \n",
    "3. **Training**:\n",
    "   - Set up a training pipeline using frameworks like `PyTorch` or `TensorFlow/Keras`.\n",
    "   - Use GPUs via `CUDA` for faster training (especially if dealing with large datasets).\n",
    "\n",
    "4. **Evaluation**:\n",
    "   - Compute metrics like BLEU score (via `nltk.translate` or `sacrebleu`).\n",
    "\n",
    "5. **Libraries and Tools**:\n",
    "   - **Core Libraries**:\n",
    "     - `torch` or `tensorflow`: For neural network building and training.\n",
    "     - `transformers`: For pre-trained models and tokenizers (e.g., BERT, T5, GPT).\n",
    "     - `sentencepiece` or `subword-nmt`: For subword tokenization.\n",
    "     - `nltk`, `spacy`: For data preprocessing and tokenization.\n",
    "   - **Performance/Optimization**:\n",
    "     - `torchtext` (for easier text preprocessing and data handling).\n",
    "     - `tensorboardX` (for logging and monitoring training).\n",
    "   - **Metrics**:\n",
    "     - `sacrebleu` or `nltk` (for BLEU score evaluation).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Breakdown of the Model:\n",
    "\n",
    "1. **Preprocessing with Subwords**:\n",
    "   - **SentencePiece or BPE**: We'll use these for subword tokenization. They allow us to break down words into smaller chunks (subwords) and handle out-of-vocabulary words effectively.\n",
    "\n",
    "2. **Seq2Seq Model with Attention**:\n",
    "   - Encoder: Typically an LSTM or GRU-based model.\n",
    "   - Decoder: LSTM/GRU-based, but with the attention mechanism to focus on different parts of the input.\n",
    "   - Attention Mechanism: We'll use the Bahdanau or Luong attention. This mechanism computes a context vector based on the encoder's hidden states and the current state of the decoder.\n",
    "\n",
    "3. **Training**:\n",
    "   - We will use teacher forcing during training to feed the actual previous token as the next input.\n",
    "   - For optimization, we'll use Adam or RMSProp.\n",
    "\n",
    "4. **Evaluation**:\n",
    "   - Use BLEU score to evaluate the quality of the translation output.\n",
    "   - Optionally, use other metrics like ROUGE or TER.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Plan\n",
    "\n",
    "### 1. **Data Preparation**\n",
    "   - **Dataset**: We'll need a parallel corpus for training, such as the [WMT](http://www.statmt.org/wmt20/) datasets or the [IWSLT](https://sites.google.com/site/iwsltevaluation2017/) datasets.\n",
    "   - **Preprocessing**: Tokenize, clean, and split the data into training, validation, and test sets.\n",
    "     - We’ll use `nltk` or `spacy` for basic tokenization.\n",
    "     - Use `sentencepiece` or `subword-nmt` to perform subword tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: nltk in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: spacy in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (3.8.2)\n",
      "Requirement already satisfied: click in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (0.14.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (2.10.2)\n",
      "Requirement already satisfied: jinja2 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (75.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece nltk spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/scales/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import sentencepiece as spm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: poem.txt\n",
      "  input_format: \n",
      "  model_prefix: model\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 77\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: poem.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 20 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=389\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=34\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 20 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=201\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 99 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 20\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 52\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 52 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=72 obj=12.4843 num_tokens=163 num_tokens/piece=2.26389\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=67 obj=11.5119 num_tokens=163 num_tokens/piece=2.43284\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: model.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: model.vocab\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of SentencePiece tokenization\n",
    "spm.SentencePieceTrainer.train(input='poem.txt', model_prefix='model', vocab_size=77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. **Model Architecture (Seq2Seq + Attention)**\n",
    "\n",
    "We'll implement a Seq2Seq model with attention in PyTorch. Here's a simplified architecture:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_dim))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = torch.sum(self.v * energy, dim=2)\n",
    "        return torch.softmax(attention, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout, attention):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.attention = attention\n",
    "        self.fc_out = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        rnn_output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        attention_weights = self.attention(hidden, encoder_outputs)\n",
    "        context_vector = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)\n",
    "        output = torch.cat((rnn_output.squeeze(1), context_vector.squeeze(1)), dim=1)\n",
    "        prediction = self.fc_out(output)\n",
    "        return prediction, hidden, cell, attention_weights\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        batch_size = src.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "\n",
    "        encoder_hidden, encoder_cell = self.encoder(src)\n",
    "\n",
    "        # First input to the decoder is the <sos> token\n",
    "        input = trg[:, 0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell, _ = self.decoder(input, encoder_hidden, encoder_cell, src)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)  \n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "        \n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Training Loop**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        # Reshape output for calculating loss\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.view(-1, output_dim)\n",
    "        trg = trg.view(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m369.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: regex in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from sacrebleu) (2024.11.6)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from sacrebleu) (2.0.2)\n",
      "Collecting colorama (from sacrebleu)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Downloading lxml-5.3.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (3.8 kB)\n",
      "Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m393.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading lxml-5.3.0-cp312-cp312-macosx_10_9_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: tabulate, portalocker, lxml, colorama, sacrebleu\n",
      "Successfully installed colorama-0.4.6 lxml-5.3.0 portalocker-3.0.0 sacrebleu-2.4.3 tabulate-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install sacrebleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    predictions, targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            output = model(src, trg, teacher_forcing_ratio=0)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.view(-1, output_dim)\n",
    "            trg = trg.view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Convert to words\n",
    "            output = output.argmax(1).cpu().numpy()\n",
    "            trg = trg.cpu().numpy()\n",
    "\n",
    "            predictions.append(output)\n",
    "            targets.append(trg)\n",
    "    \n",
    "    # BLEU score calculation\n",
    "    bleu_score = sacrebleu.corpus_bleu(predictions, [targets]).score\n",
    "    return epoch_loss / len(iterator), bleu_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. **Training and Evaluation**\n",
    "\n",
    "Set up the data loaders, optimizer, and loss function.\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- **Data Handling**: Implement data loading, preprocessing (tokenization, padding).\n",
    "- **Hyperparameter Tuning**: Adjust hidden layer sizes, embedding dimensions, etc.\n",
    "- **Optimization**: Test the model with different batch sizes, learning rates, etc.\n",
    "\n",
    "Let me know how you'd like to proceed or if you'd like further details on any part!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
