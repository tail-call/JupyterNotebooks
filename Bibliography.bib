%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Flickering Glow at 2024-11-14 18:55:00 +0700 


%% Saved with string encoding Unicode (UTF-8) 



@book{automl-mcs,
	author = {Frank Hutter},
	date-added = {2024-11-14 18:44:43 +0700},
	date-modified = {2024-11-14 18:52:23 +0700},
	keywords = {machine learning, automl, automation},
	publisher = {Springer},
	title = {Automated Machine Learning: Methods, Systems, Challenges},
	year = {2018}}

@webpage{tail-call-github,
	date-added = {2024-11-14 18:43:27 +0700},
	date-modified = {2024-11-14 18:44:10 +0700},
	lastchecked = {2024-11-14},
	url = {https://github.com/tail-call},
	bdsk-url-1 = {https://github.com/tail-call}}

@article{Fan_2024,
	abstract = {This paper investigates the stability of deep ReLU neural networks for nonparametric regression under the assumption that the noise has only a finite pth moment. We unveil how the optimal rate of convergence depends on p, the degree of smoothness and the intrinsic dimension in a class of nonparametric regression functions with hierarchical composition structure when both the adaptive Huber loss and deep ReLU neural networks are used. This optimal rate of convergence cannot be obtained by the ordinary least squares but can be achieved by the Huber loss with a properly chosen parameter that adapts to the sample size, smoothness, and moment parameters. A concentration inequality for the adaptive Huber ReLU neural network estimators with allowable optimization errors is also derived. To establish a matching lower bound within the class of neural network estimators using the Huber loss, we employ a different strategy from the traditional route: constructing a deep ReLU network estimator that has a better empirical loss than the true function and the difference between these two functions furnishes a low bound. This step is related to the Huberization bias, yet more critically to the approximability of deep ReLU networks. As a result, we also contribute some new results on the approximation theory of deep ReLU neural networks.},
	author = {Fan, Jianqing and Gu, Yihong and Zhou, Wen-Xin},
	date-added = {2024-11-14 18:38:05 +0700},
	date-modified = {2024-11-14 18:53:20 +0700},
	doi = {10.1214/24-aos2428},
	issn = {0090-5364},
	journal = {The Annals of Statistics},
	keywords = {approximablility of ReLU networks , composition of functions , heavy tails , Optimal rates , robustness , truncation, machine learning},
	month = aug,
	number = {4},
	publisher = {Institute of Mathematical Statistics},
	title = {How do noise tails impact on deep ReLU networks?},
	url = {http://dx.doi.org/10.1214/24-AOS2428},
	volume = {52},
	year = {2024},
	bdsk-url-1 = {http://dx.doi.org/10.1214/24-AOS2428}}

@article{hall2023,
	abstract = {The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), leading to remarkable advancements in text understand- ing and generation. Nevertheless, alongside these strides, LLMs exhibit a critical tendency to produce hallucinations, resulting in content that is inconsistent with real-world facts or user inputs. This phenomenon poses substantial challenges to their practical deployment and raises concerns over the reliability of LLMs in real-world scenarios, which attracts increasing attention to detect and mitigate these hallucina- tions. In this survey, we aim to provide a thor- ough and in-depth overview of recent advances in the field of LLM hallucinations. We begin with an innovative taxonomy of LLM halluci- nations, then delve into the factors contributing to hallucinations. Subsequently, we present a comprehensive overview of hallucination de- tection methods and benchmarks. Additionally, representative approaches designed to mitigate hallucinations are introduced accordingly. Fi- nally, we analyze the challenges that highlight the current limitations and formulate open ques- tions, aiming to delineate pathways for future research on hallucinations in LLMs. },
	author = {Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, Ting Liu},
	date-added = {2024-11-14 11:11:20 +0700},
	date-modified = {2024-11-14 18:54:40 +0700},
	keywords = {nlp, llm, hallucination, survey},
	rating = {3},
	read = {0},
	title = {Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhYYm9va21hcmtfEHwuLi9TdHVkeS9QYXBlcnMvQSBTdXJ2ZXkgb24gSGFsbHVjaW5hdGlvbiBpbiBMYXJnZSBMYW5ndWFnZSBNb2RlbHMtIFByaW5jaXBsZXMsIFRheG9ub215LCBDaGFsbGVuZ2VzLCBhbmQgT3BlbiBRdWVzdGlvbnMucGRmTxEEeGJvb2t4BAAAAAAEEDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHQDAAAFAAAAAQEAAFVzZXJzAAAABgAAAAEBAABzY2FsZXMAAAUAAAABAQAAU3R1ZHkAAAAGAAAAAQEAAFBhcGVycwAAbAAAAAEBAABBIFN1cnZleSBvbiBIYWxsdWNpbmF0aW9uIGluIExhcmdlIExhbmd1YWdlIE1vZGVscy0gUHJpbmNpcGxlcywgVGF4b25vbXksIENoYWxsZW5nZXMsIGFuZCBPcGVuIFF1ZXN0aW9ucy5wZGYUAAAAAQYAAAQAAAAUAAAAJAAAADQAAABEAAAACAAAAAQDAAClQQAAAAAAAAgAAAAEAwAAKdoFAAAAAAAIAAAABAMAACuYJAAAAAAACAAAAAQDAABzx18AAAAAAAgAAAAEAwAAis50AAAAAAAUAAAAAQYAANQAAADkAAAA9AAAAAQBAAAUAQAACAAAAAAEAABBxkYtyrKBohgAAAABAgAAAQAAAAAAAAAPAAAAAAAAAAAAAAAAAAAACAAAAAQDAAADAAAAAAAAAAQAAAADAwAA9wEAAAgAAAABCQAAZmlsZTovLy8MAAAAAQEAAE1hY2ludG9zaCBIRAgAAAAEAwAAAJCClucAAAAIAAAAAAQAAEHGL8gGgAAAJAAAAAEBAAA0Mzg3NjU4NC00QjY4LTRFQTMtQjAwMi1FNDRBNEI5MkFENEMYAAAAAQIAAIEAAAABAAAA7xMAAAEAAAAAAAAAAAAAAAEAAAABAQAALwAAAAAAAAABBQAAOQEAAAECAAAzNDk2MGY5NDQ3NGZhZmU3YjdlYzc5NWVhYTdiNjNhZDI1YmUwZjEwNTE5MjFjNjFkYjQxZjFiMGVhNTcyZTYzOzAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwOzAwMDAwMDAwMDAwMDAwMjA7Y29tLmFwcGxlLmFwcC1zYW5kYm94LnJlYWQtd3JpdGU7MDE7MDEwMDAwMTA7MDAwMDAwMDAwMDc0Y2U4YTswMTsvdXNlcnMvc2NhbGVzL3N0dWR5L3BhcGVycy9hIHN1cnZleSBvbiBoYWxsdWNpbmF0aW9uIGluIGxhcmdlIGxhbmd1YWdlIG1vZGVscy0gcHJpbmNpcGxlcywgdGF4b25vbXksIGNoYWxsZW5nZXMsIGFuZCBvcGVuIHF1ZXN0aW9ucy5wZGYAAAAAzAAAAP7///8BAAAAAAAAABAAAAAEEAAAuAAAAAAAAAAFEAAAJAEAAAAAAAAQEAAAUAEAAAAAAABAEAAAQAEAAAAAAAACIAAAHAIAAAAAAAAFIAAAjAEAAAAAAAAQIAAAnAEAAAAAAAARIAAA0AEAAAAAAAASIAAAsAEAAAAAAAATIAAAwAEAAAAAAAAgIAAA/AEAAAAAAAAwIAAAKAIAAAAAAAABwAAAcAEAAAAAAAARwAAAFAAAAAAAAAASwAAAgAEAAAAAAACA8AAAMAIAAAAAAAAACAANABoAIwCiAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAABR4=}}
