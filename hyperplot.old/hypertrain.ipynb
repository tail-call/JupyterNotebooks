{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Композиционная теория игр и нейросети: эксперимент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Теория**: И.В.Томилов ivan-tomilov3@yandex.ru\n",
    "- **Реализация**: М.А.Зайцева maria@tail-call.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (0.17.2)\n",
      "Requirement already satisfied: numpy<2 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/scales/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision 'numpy<2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    train_dataset: datasets.MNIST\n",
    "    test_dataset: datasets.MNIST\n",
    "    train_loader: torch.utils.data.DataLoader\n",
    "    test_loader: torch.utils.data.DataLoader\n",
    "\n",
    "def make_dataset(root: str, batch_size: int) -> Dataset:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST(\n",
    "        root=root,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    test_dataset = datasets.MNIST(\n",
    "        root=root,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    return Dataset(\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        train_loader=torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True\n",
    "        ),\n",
    "        test_loader=torch.utils.data.DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "dataset = make_dataset(root='./data', batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw(tensor: torch.Tensor):\n",
    "    plt.imshow(tensor, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "draw(dataset.test_dataset.data[9])\n",
    "draw(dataset.test_dataset.data[2])\n",
    "draw(dataset.test_dataset.data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DigitRecognizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitRecognizer, self).__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(28 * 28, 32 * 32)\n",
    "        self.fc2 = nn.Linear(32 * 32, 32 * 32)\n",
    "        self.fc3 = nn.Linear(32 * 32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train(model: DigitRecognizer, loader, epochs, criterion, optimizer):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 100 == 99:\n",
    "                print(f'E{epoch + 1}/{epochs} S{i + 1}/{len(loader)} Loss={running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1/5 S100/938 Loss=0.4769\n",
      "E1/5 S200/938 Loss=0.2553\n",
      "E1/5 S300/938 Loss=0.1866\n",
      "E1/5 S400/938 Loss=0.1697\n",
      "E1/5 S500/938 Loss=0.1473\n",
      "E1/5 S600/938 Loss=0.1449\n",
      "E1/5 S700/938 Loss=0.1337\n",
      "E1/5 S800/938 Loss=0.1338\n",
      "E1/5 S900/938 Loss=0.1193\n",
      "E2/5 S100/938 Loss=0.0884\n",
      "E2/5 S200/938 Loss=0.0892\n",
      "E2/5 S300/938 Loss=0.0922\n",
      "E2/5 S400/938 Loss=0.0780\n",
      "E2/5 S500/938 Loss=0.0987\n",
      "E2/5 S600/938 Loss=0.0923\n",
      "E2/5 S700/938 Loss=0.0814\n",
      "E2/5 S800/938 Loss=0.0852\n",
      "E2/5 S900/938 Loss=0.1043\n",
      "E3/5 S100/938 Loss=0.0552\n",
      "E3/5 S200/938 Loss=0.0563\n",
      "E3/5 S300/938 Loss=0.0590\n",
      "E3/5 S400/938 Loss=0.0644\n",
      "E3/5 S500/938 Loss=0.0682\n",
      "E3/5 S600/938 Loss=0.0683\n",
      "E3/5 S700/938 Loss=0.0684\n",
      "E3/5 S800/938 Loss=0.0671\n",
      "E3/5 S900/938 Loss=0.0609\n",
      "E4/5 S100/938 Loss=0.0528\n",
      "E4/5 S200/938 Loss=0.0470\n",
      "E4/5 S300/938 Loss=0.0359\n",
      "E4/5 S400/938 Loss=0.0374\n",
      "E4/5 S500/938 Loss=0.0437\n",
      "E4/5 S600/938 Loss=0.0458\n",
      "E4/5 S700/938 Loss=0.0465\n",
      "E4/5 S800/938 Loss=0.0575\n",
      "E4/5 S900/938 Loss=0.0502\n",
      "E5/5 S100/938 Loss=0.0302\n",
      "E5/5 S200/938 Loss=0.0412\n",
      "E5/5 S300/938 Loss=0.0372\n",
      "E5/5 S400/938 Loss=0.0496\n",
      "E5/5 S500/938 Loss=0.0381\n",
      "E5/5 S600/938 Loss=0.0384\n",
      "E5/5 S700/938 Loss=0.0522\n",
      "E5/5 S800/938 Loss=0.0458\n",
      "E5/5 S900/938 Loss=0.0501\n"
     ]
    }
   ],
   "source": [
    "model = DigitRecognizer()\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    loader=dataset.train_loader,\n",
    "    epochs=5,\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=0.001\n",
    "    )\n",
    ")\n",
    "\n",
    "torch.save(model.state_dict(), 'digit_recognizer.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.8%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model = DigitRecognizer()\n",
    "model.load_state_dict(torch.load('digit_recognizer.pth'))\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataset.test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy: {correct / total * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 39.7960, -42.5919, -14.6548, -19.3560, -21.8696, -25.8399,  -7.7096,\n",
      "        -29.1079, -15.5656,  -7.7908], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, tensor([0]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = DigitRecognizer()\n",
    "model.load_state_dict(torch.load('digit_recognizer.pth'))\n",
    "\n",
    "idx = 997 \n",
    "\n",
    "draw(dataset.test_dataset.data[idx])\n",
    "\n",
    "(x, y) = dataset.test_dataset[idx]\n",
    "\n",
    "outputs = model(x)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print(outputs[0])\n",
    "\n",
    "(y, predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
